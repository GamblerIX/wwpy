#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¸£æ½®æœåŠ¡å™¨æ—¥å¿—ç®¡ç†è„šæœ¬

åŠŸèƒ½ï¼š
- æ—¥å¿—æ–‡ä»¶æŸ¥çœ‹å’Œåˆ†æ
- æ—¥å¿—æ–‡ä»¶ç®¡ç†ï¼ˆæ¸…ç†ã€å½’æ¡£ï¼‰
- å®æ—¶æ—¥å¿—ç›‘æ§
- é”™è¯¯æ—¥å¿—è¿‡æ»¤
- æ—¥å¿—ç»Ÿè®¡åˆ†æ
"""

import os
import re
import sys
import time
import gzip
import shutil
from pathlib import Path
from datetime import datetime, timedelta
from threading import Thread, Event
from collections import defaultdict, Counter

class WuWaLogs:
    """é¸£æ½®æœåŠ¡å™¨æ—¥å¿—ç®¡ç†ç±»"""
    
    def __init__(self, project_root):
        self.project_root = Path(project_root)
        self.logs_dir = self.project_root / "logs"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.logs_dir.mkdir(exist_ok=True)
        
        # æ—¥å¿—æ–‡ä»¶é…ç½®
        self.log_files = {
            "build": "build.log",
            "run": "run.log",
            "status": "status.log",
            "config": "config-server.log",
            "hotpatch": "hotpatch-server.log",
            "login": "login-server.log",
            "gateway": "gateway-server.log",
            "game": "game-server.log"
        }
        
        # æ—¥å¿—çº§åˆ«é¢œè‰²
        self.log_colors = {
            "ERROR": "\033[91m",    # çº¢è‰²
            "WARN": "\033[93m",     # é»„è‰²
            "WARNING": "\033[93m",  # é»„è‰²
            "INFO": "\033[92m",     # ç»¿è‰²
            "DEBUG": "\033[94m",    # è“è‰²
            "RESET": "\033[0m"      # é‡ç½®
        }
        
        # ç›‘æ§æ ‡å¿—
        self.monitoring = False
        self.monitor_event = Event()
        
    def log_message(self, message, log_type="INFO"):
        """è®°å½•æ—¥å¿—æ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] [{log_type}] {message}"
        
        # è¾“å‡ºåˆ°æ§åˆ¶å°
        print(log_entry)
        
        # å†™å…¥æ—¥å¿—æ–‡ä»¶
        log_file = self.logs_dir / "logs.log"
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(log_entry + "\n")
            
    def get_log_files_info(self):
        """è·å–æ—¥å¿—æ–‡ä»¶ä¿¡æ¯"""
        files_info = {}
        
        for log_key, log_filename in self.log_files.items():
            log_path = self.logs_dir / log_filename
            
            if log_path.exists():
                stat = log_path.stat()
                files_info[log_key] = {
                    "filename": log_filename,
                    "path": log_path,
                    "size_bytes": stat.st_size,
                    "size_mb": stat.st_size / 1024 / 1024,
                    "modified_time": datetime.fromtimestamp(stat.st_mtime),
                    "exists": True
                }
            else:
                files_info[log_key] = {
                    "filename": log_filename,
                    "path": log_path,
                    "size_bytes": 0,
                    "size_mb": 0,
                    "modified_time": None,
                    "exists": False
                }
                
        return files_info
        
    def show_log_files_list(self):
        """æ˜¾ç¤ºæ—¥å¿—æ–‡ä»¶åˆ—è¡¨"""
        print("\n" + "=" * 80)
        print("                        é¸£æ½®æœåŠ¡å™¨æ—¥å¿—æ–‡ä»¶")
        print("=" * 80)
        
        files_info = self.get_log_files_info()
        
        print(f"{'åºå·':<4} {'ç±»å‹':<12} {'æ–‡ä»¶å':<25} {'å¤§å°':<10} {'æœ€åä¿®æ”¹æ—¶é—´':<20} {'çŠ¶æ€':<8}")
        print("-" * 80)
        
        for i, (log_key, info) in enumerate(files_info.items(), 1):
            if info['exists']:
                size_str = f"{info['size_mb']:.1f} MB"
                mtime_str = info['modified_time'].strftime("%Y-%m-%d %H:%M:%S")
                status = "å­˜åœ¨"
            else:
                size_str = "0 MB"
                mtime_str = "-"
                status = "ä¸å­˜åœ¨"
                
            print(f"{i:<4} {log_key:<12} {info['filename']:<25} {size_str:<10} {mtime_str:<20} {status:<8}")
            
        print("\n" + "=" * 80)
        
    def read_log_file(self, log_key, lines=50, follow=False):
        """è¯»å–æ—¥å¿—æ–‡ä»¶"""
        if log_key not in self.log_files:
            print(f"é”™è¯¯: æœªçŸ¥çš„æ—¥å¿—ç±»å‹ '{log_key}'")
            return
            
        log_path = self.logs_dir / self.log_files[log_key]
        
        if not log_path.exists():
            print(f"æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_path}")
            return
            
        try:
            if follow:
                self._follow_log_file(log_path)
            else:
                self._read_log_lines(log_path, lines)
        except Exception as e:
            self.log_message(f"è¯»å–æ—¥å¿—æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}", "ERROR")
            
    def _read_log_lines(self, log_path, lines):
        """è¯»å–æ—¥å¿—æ–‡ä»¶çš„æœ€åå‡ è¡Œ"""
        print(f"\nğŸ“„ æ—¥å¿—æ–‡ä»¶: {log_path.name}")
        print(f"ğŸ“… æœ€å {lines} è¡Œå†…å®¹:")
        print("-" * 80)
        
        try:
            with open(log_path, "r", encoding="utf-8") as f:
                # è¯»å–æ‰€æœ‰è¡Œ
                all_lines = f.readlines()
                
                # è·å–æœ€åå‡ è¡Œ
                last_lines = all_lines[-lines:] if len(all_lines) > lines else all_lines
                
                for line in last_lines:
                    colored_line = self._colorize_log_line(line.rstrip())
                    print(colored_line)
                    
        except UnicodeDecodeError:
            # å°è¯•å…¶ä»–ç¼–ç 
            try:
                with open(log_path, "r", encoding="gbk") as f:
                    all_lines = f.readlines()
                    last_lines = all_lines[-lines:] if len(all_lines) > lines else all_lines
                    
                    for line in last_lines:
                        colored_line = self._colorize_log_line(line.rstrip())
                        print(colored_line)
            except Exception as e:
                print(f"æ— æ³•è¯»å–æ–‡ä»¶ (ç¼–ç é”™è¯¯): {e}")
                
        print("-" * 80)
        
    def _follow_log_file(self, log_path):
        """å®æ—¶è·Ÿè¸ªæ—¥å¿—æ–‡ä»¶"""
        print(f"\nğŸ“„ å®æ—¶ç›‘æ§æ—¥å¿—æ–‡ä»¶: {log_path.name}")
        print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        print("-" * 80)
        
        try:
            with open(log_path, "r", encoding="utf-8") as f:
                # ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾
                f.seek(0, 2)
                
                while True:
                    line = f.readline()
                    if line:
                        colored_line = self._colorize_log_line(line.rstrip())
                        print(colored_line)
                    else:
                        time.sleep(0.1)
                        
        except KeyboardInterrupt:
            print("\nç›‘æ§å·²åœæ­¢")
        except Exception as e:
            print(f"ç›‘æ§æ—¥å¿—æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            
    def _colorize_log_line(self, line):
        """ä¸ºæ—¥å¿—è¡Œæ·»åŠ é¢œè‰²"""
        # æ£€æŸ¥æ—¥å¿—çº§åˆ«
        for level, color in self.log_colors.items():
            if level == "RESET":
                continue
                
            if f"[{level}]" in line or f" {level} " in line:
                return f"{color}{line}{self.log_colors['RESET']}"
                
        return line
        
    def search_logs(self, pattern, log_keys=None, case_sensitive=False):
        """æœç´¢æ—¥å¿—å†…å®¹"""
        if log_keys is None:
            log_keys = list(self.log_files.keys())
        elif isinstance(log_keys, str):
            log_keys = [log_keys]
            
        print(f"\nğŸ” æœç´¢æ¨¡å¼: '{pattern}'")
        print(f"ğŸ“ æœç´¢èŒƒå›´: {', '.join(log_keys)}")
        print("-" * 80)
        
        total_matches = 0
        flags = 0 if case_sensitive else re.IGNORECASE
        
        try:
            regex = re.compile(pattern, flags)
        except re.error as e:
            print(f"æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯: {e}")
            return
            
        for log_key in log_keys:
            if log_key not in self.log_files:
                continue
                
            log_path = self.logs_dir / self.log_files[log_key]
            if not log_path.exists():
                continue
                
            matches = self._search_in_file(log_path, regex)
            if matches:
                print(f"\nğŸ“„ {log_path.name} ({len(matches)} ä¸ªåŒ¹é…):")
                for line_num, line in matches:
                    colored_line = self._colorize_log_line(line)
                    print(f"  {line_num:4}: {colored_line}")
                total_matches += len(matches)
                
        print(f"\nğŸ¯ æ€»å…±æ‰¾åˆ° {total_matches} ä¸ªåŒ¹é…é¡¹")
        
    def _search_in_file(self, file_path, regex, max_matches=100):
        """åœ¨æ–‡ä»¶ä¸­æœç´¢åŒ¹é…é¡¹"""
        matches = []
        
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                for line_num, line in enumerate(f, 1):
                    if regex.search(line):
                        matches.append((line_num, line.rstrip()))
                        if len(matches) >= max_matches:
                            break
        except UnicodeDecodeError:
            try:
                with open(file_path, "r", encoding="gbk") as f:
                    for line_num, line in enumerate(f, 1):
                        if regex.search(line):
                            matches.append((line_num, line.rstrip()))
                            if len(matches) >= max_matches:
                                break
            except Exception:
                pass
        except Exception:
            pass
            
        return matches
        
    def analyze_logs(self, log_keys=None, hours=24):
        """åˆ†ææ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
        if log_keys is None:
            log_keys = list(self.log_files.keys())
        elif isinstance(log_keys, str):
            log_keys = [log_keys]
            
        print(f"\nğŸ“Š æ—¥å¿—åˆ†æ (æœ€è¿‘ {hours} å°æ—¶)")
        print("=" * 80)
        
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        total_stats = {
            "total_lines": 0,
            "error_count": 0,
            "warning_count": 0,
            "info_count": 0,
            "debug_count": 0,
            "hourly_distribution": defaultdict(int),
            "error_messages": Counter()
        }
        
        for log_key in log_keys:
            if log_key not in self.log_files:
                continue
                
            log_path = self.logs_dir / self.log_files[log_key]
            if not log_path.exists():
                continue
                
            print(f"\nğŸ“„ åˆ†æ {log_path.name}:")
            file_stats = self._analyze_log_file(log_path, cutoff_time)
            
            if file_stats:
                print(f"  æ€»è¡Œæ•°: {file_stats['total_lines']}")
                print(f"  é”™è¯¯: {file_stats['error_count']}")
                print(f"  è­¦å‘Š: {file_stats['warning_count']}")
                print(f"  ä¿¡æ¯: {file_stats['info_count']}")
                print(f"  è°ƒè¯•: {file_stats['debug_count']}")
                
                # åˆå¹¶ç»Ÿè®¡
                for key in ['total_lines', 'error_count', 'warning_count', 'info_count', 'debug_count']:
                    total_stats[key] += file_stats[key]
                    
                for hour, count in file_stats['hourly_distribution'].items():
                    total_stats['hourly_distribution'][hour] += count
                    
                total_stats['error_messages'].update(file_stats['error_messages'])
            else:
                print("  æ— æ•°æ®æˆ–æ–‡ä»¶ä¸ºç©º")
                
        # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
        print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print("-" * 40)
        print(f"æ€»è¡Œæ•°: {total_stats['total_lines']}")
        print(f"é”™è¯¯: {total_stats['error_count']}")
        print(f"è­¦å‘Š: {total_stats['warning_count']}")
        print(f"ä¿¡æ¯: {total_stats['info_count']}")
        print(f"è°ƒè¯•: {total_stats['debug_count']}")
        
        # æ˜¾ç¤ºæ¯å°æ—¶åˆ†å¸ƒ
        if total_stats['hourly_distribution']:
            print(f"\nâ° æ¯å°æ—¶æ—¥å¿—åˆ†å¸ƒ:")
            print("-" * 40)
            sorted_hours = sorted(total_stats['hourly_distribution'].items())
            for hour, count in sorted_hours[-12:]:  # æ˜¾ç¤ºæœ€è¿‘12å°æ—¶
                bar = "â–ˆ" * min(count // 10, 50)  # ç®€å•çš„æ¡å½¢å›¾
                print(f"  {hour:2}æ—¶: {count:4} {bar}")
                
        # æ˜¾ç¤ºå¸¸è§é”™è¯¯
        if total_stats['error_messages']:
            print(f"\nğŸš¨ å¸¸è§é”™è¯¯ (å‰5ä¸ª):")
            print("-" * 40)
            for error, count in total_stats['error_messages'].most_common(5):
                print(f"  {count:3}x {error[:60]}..." if len(error) > 60 else f"  {count:3}x {error}")
                
        print("\n" + "=" * 80)
        
    def _analyze_log_file(self, file_path, cutoff_time):
        """åˆ†æå•ä¸ªæ—¥å¿—æ–‡ä»¶"""
        stats = {
            "total_lines": 0,
            "error_count": 0,
            "warning_count": 0,
            "info_count": 0,
            "debug_count": 0,
            "hourly_distribution": defaultdict(int),
            "error_messages": Counter()
        }
        
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                for line in f:
                    stats['total_lines'] += 1
                    
                    # æå–æ—¶é—´æˆ³
                    timestamp = self._extract_timestamp(line)
                    if timestamp and timestamp >= cutoff_time:
                        hour = timestamp.hour
                        stats['hourly_distribution'][hour] += 1
                        
                        # ç»Ÿè®¡æ—¥å¿—çº§åˆ«
                        if '[ERROR]' in line or ' ERROR ' in line:
                            stats['error_count'] += 1
                            # æå–é”™è¯¯æ¶ˆæ¯
                            error_msg = self._extract_error_message(line)
                            if error_msg:
                                stats['error_messages'][error_msg] += 1
                        elif '[WARN]' in line or '[WARNING]' in line or ' WARN ' in line:
                            stats['warning_count'] += 1
                        elif '[INFO]' in line or ' INFO ' in line:
                            stats['info_count'] += 1
                        elif '[DEBUG]' in line or ' DEBUG ' in line:
                            stats['debug_count'] += 1
                            
        except UnicodeDecodeError:
            try:
                with open(file_path, "r", encoding="gbk") as f:
                    # é‡å¤ç›¸åŒçš„é€»è¾‘
                    for line in f:
                        stats['total_lines'] += 1
                        # ... (ç›¸åŒçš„å¤„ç†é€»è¾‘)
            except Exception:
                return None
        except Exception:
            return None
            
        return stats
        
    def _extract_timestamp(self, line):
        """ä»æ—¥å¿—è¡Œä¸­æå–æ—¶é—´æˆ³"""
        # å¸¸è§çš„æ—¶é—´æˆ³æ ¼å¼
        patterns = [
            r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]',
            r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})',
            r'(\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2})'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, line)
            if match:
                try:
                    timestamp_str = match.group(1)
                    # å°è¯•ä¸åŒçš„æ—¶é—´æ ¼å¼
                    for fmt in ['%Y-%m-%d %H:%M:%S', '%Y/%m/%d %H:%M:%S']:
                        try:
                            return datetime.strptime(timestamp_str, fmt)
                        except ValueError:
                            continue
                except Exception:
                    pass
                    
        return None
        
    def _extract_error_message(self, line):
        """ä»é”™è¯¯æ—¥å¿—è¡Œä¸­æå–é”™è¯¯æ¶ˆæ¯"""
        # å°è¯•æå–é”™è¯¯æ¶ˆæ¯çš„ä¸»è¦éƒ¨åˆ†
        patterns = [
            r'\[ERROR\]\s*(.+)',
            r'ERROR:\s*(.+)',
            r'Error:\s*(.+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, line, re.IGNORECASE)
            if match:
                error_msg = match.group(1).strip()
                # æˆªå–å‰100ä¸ªå­—ç¬¦
                return error_msg[:100] if len(error_msg) > 100 else error_msg
                
        return None
        
    def clean_logs(self, days_to_keep=7, compress_old=True):
        """æ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶"""
        print(f"\nğŸ§¹ æ¸…ç†æ—¥å¿—æ–‡ä»¶ (ä¿ç•™æœ€è¿‘ {days_to_keep} å¤©)")
        print("=" * 60)
        
        cutoff_time = datetime.now() - timedelta(days=days_to_keep)
        cleaned_files = []
        compressed_files = []
        
        # æ¸…ç†ä¸»æ—¥å¿—æ–‡ä»¶
        for log_key, log_filename in self.log_files.items():
            log_path = self.logs_dir / log_filename
            
            if log_path.exists():
                stat = log_path.stat()
                mtime = datetime.fromtimestamp(stat.st_mtime)
                
                if mtime < cutoff_time:
                    if compress_old:
                        # å‹ç¼©æ—§æ–‡ä»¶
                        compressed_path = self._compress_log_file(log_path)
                        if compressed_path:
                            compressed_files.append(compressed_path)
                            log_path.unlink()  # åˆ é™¤åŸæ–‡ä»¶
                            cleaned_files.append(log_filename)
                    else:
                        # ç›´æ¥åˆ é™¤
                        log_path.unlink()
                        cleaned_files.append(log_filename)
                        
        # æ¸…ç†çŠ¶æ€æŠ¥å‘Šæ–‡ä»¶
        report_pattern = "status_report_*.txt"
        for report_file in self.logs_dir.glob(report_pattern):
            stat = report_file.stat()
            mtime = datetime.fromtimestamp(stat.st_mtime)
            
            if mtime < cutoff_time:
                report_file.unlink()
                cleaned_files.append(report_file.name)
                
        # æ˜¾ç¤ºç»“æœ
        if cleaned_files:
            print(f"âœ… å·²æ¸…ç† {len(cleaned_files)} ä¸ªæ–‡ä»¶:")
            for filename in cleaned_files:
                print(f"  - {filename}")
        else:
            print("â„¹ï¸  æ²¡æœ‰éœ€è¦æ¸…ç†çš„æ–‡ä»¶")
            
        if compressed_files:
            print(f"\nğŸ“¦ å·²å‹ç¼© {len(compressed_files)} ä¸ªæ–‡ä»¶:")
            for filepath in compressed_files:
                print(f"  - {filepath.name}")
                
        print("\n" + "=" * 60)
        
    def _compress_log_file(self, log_path):
        """å‹ç¼©æ—¥å¿—æ–‡ä»¶"""
        try:
            compressed_path = log_path.with_suffix(log_path.suffix + '.gz')
            
            with open(log_path, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
                    
            return compressed_path
        except Exception as e:
            self.log_message(f"å‹ç¼©æ–‡ä»¶å¤±è´¥ {log_path}: {e}", "ERROR")
            return None
            
    def export_logs(self, output_dir, log_keys=None, date_range=None):
        """å¯¼å‡ºæ—¥å¿—æ–‡ä»¶"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        if log_keys is None:
            log_keys = list(self.log_files.keys())
        elif isinstance(log_keys, str):
            log_keys = [log_keys]
            
        print(f"\nğŸ“¤ å¯¼å‡ºæ—¥å¿—åˆ°: {output_path}")
        print("=" * 60)
        
        exported_files = []
        
        for log_key in log_keys:
            if log_key not in self.log_files:
                continue
                
            log_path = self.logs_dir / self.log_files[log_key]
            if not log_path.exists():
                continue
                
            # ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            export_filename = f"{log_key}_{timestamp}.log"
            export_path = output_path / export_filename
            
            try:
                if date_range:
                    # æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤
                    self._export_filtered_log(log_path, export_path, date_range)
                else:
                    # ç›´æ¥å¤åˆ¶
                    shutil.copy2(log_path, export_path)
                    
                exported_files.append(export_filename)
                print(f"âœ… {log_key}: {export_filename}")
                
            except Exception as e:
                print(f"âŒ {log_key}: å¯¼å‡ºå¤±è´¥ - {e}")
                
        print(f"\nğŸ“Š æ€»è®¡å¯¼å‡º {len(exported_files)} ä¸ªæ–‡ä»¶")
        print("\n" + "=" * 60)
        
    def _export_filtered_log(self, source_path, target_path, date_range):
        """æŒ‰æ—¥æœŸèŒƒå›´å¯¼å‡ºæ—¥å¿—"""
        start_date, end_date = date_range
        
        with open(source_path, "r", encoding="utf-8") as f_in:
            with open(target_path, "w", encoding="utf-8") as f_out:
                for line in f_in:
                    timestamp = self._extract_timestamp(line)
                    if timestamp and start_date <= timestamp <= end_date:
                        f_out.write(line)

def main():
    """æµ‹è¯•å‡½æ•°"""
    project_root = Path(__file__).parent.parent
    log_manager = WuWaLogs(project_root)
    
    print("æ—¥å¿—ç®¡ç†æµ‹è¯•...")
    
    # æ˜¾ç¤ºæ—¥å¿—æ–‡ä»¶åˆ—è¡¨
    log_manager.show_log_files_list()
    
    # åˆ†ææ—¥å¿—
    log_manager.analyze_logs(hours=24)

if __name__ == "__main__":
    main()